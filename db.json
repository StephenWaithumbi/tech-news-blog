{
  "blogs": [
    {
      "id": "9c46",
      "title": "Using AI technologies for future asset management",
      "body": "Fixed asset management is a critical feature for organisations to manage, control, and optimise the value of their physical assets. Assets can include everything from equipment and vehicles to home computer systems. Traditionally, manual asset management systems entail manual report maintenance and periodic audits, which can be time-consuming and susceptible to human error.\n\nAI-driven fixed assets software offers a modern solution by automating diverse asset control factors. This guarantees accuracy, reduces administrative overhead, and increases an asset’s useful life, ultimately contributing to significant cost savings. AI, blended with the Internet of Things (IoT), machine learning (ML), and predictive analytics, is the primary method to develop smart, efficient, and scalable asset management solutions.\n\nThe predictive capacities of AI revolutionise proactive asset management. AI can predict when a piece of hardware is likely to fail or spot chances for optimisation by evaluating patterns and trends in data. The proactive strategy not only helps with strategic planning but also ensures the reliability of operations by preventing system outages that can cause serious disruptions to business operations and financial losses. Businesses may use AI to ensure their assets operate at peak efficiency, quickly adopt new technologies, and match operations to corporate goals.",
      "image": "https://www.artificialintelligence-news.com/wp-content/uploads/2024/11/Picture3.png",
      "topic": "ai",
      "author": "James"
    },
    {
      "id": "82f0",
      "title": "Developers get a better shot at App Store spotlight",
      "body": "Developers can access the nominations dashboard within App Store Connect, where they can submit individual app or game features for consideration. Larger publishers with multiple releases now also have the option to upload spreadsheets for bulk nominations. \n\nApple encourages developers to choose memorable names for their nominations, clearly outlining the focus of the update or new content. A detailed text description should accompany the name, providing specific details about the update and its anticipated launch date.\n\nFurthermore, a “Helpful Details” section allows developers to share additional context, such as the app’s development story, unique features, accessibility improvements, or innovative use of developer tools. This added layer provides valuable insight into the app and its merits for the App Store editorial team.\n\nOnce an app is selected for featuring, developers will receive a notification within App Store Connect. This notification links to a dedicated page where they can access promotional assets designed to maximise the impact of their featured status. These assets empower developers to quickly share the news across social media platforms and other marketing channels, driving traffic to their apps.\n\nApple says that it also plans to provide marketing materials for other key moments in an app’s lifecycle, such as initial launches or major updates, ensuring continuous support for developer success.",
      "image": "https://www.developer-tech.com/wp-content/uploads/2024/11/Picture2.png",
      "topic": "software engineering",
      "author": "John"
    },
    {
      "id": "2640",
      "title": "Russian Hackers Exploit New NTLM Flaw to Deploy RAT Malware via Phishing Emails",
      "body": "A newly patched security flaw impacting Windows NT LAN Manager (NTLM) was exploited as a zero-day by a suspected Russia-linked actor as part of cyber attacks targeting Ukraine.\n\nThe vulnerability in question, CVE-2024-43451 (CVSS score: 6.5), refers to an NTLM hash disclosure spoofing vulnerability that could be exploited to steal a user's NTLMv2 hash. It was patched by Microsoft earlier this week.\n\n\"Minimal interaction with a malicious file by a user such as selecting (single-click), inspecting (right-click), or performing an action other than opening or executing could trigger this vulnerability,\" Microsoft revealed in its advisory.\nIsraeli cybersecurity company ClearSky, which discovered the zero-day exploitation of the flaw in June 2024, said it's been abused as part of an attack chain that delivers the open-source Spark RAT malware.\n\n\"The vulnerability activates URL files, leading to malicious activity,\" the company said, adding the malicious files were hosted on an official Ukrainian government site that allows users to download academic certificates.\n\nThe attack chain involves sending phishing emails from a compromised Ukrainian government server (\"doc.osvita-kp.gov[.]ua\") that prompts recipients to renew their academic certificates by clicking on a booby-trapped URL embedded in the message.\n\nThis leads to the download of a ZIP archive containing a malicious internet shortcut (.URL) file. The vulnerability is triggered when the victim interacts with the URL file by right-clicking, deleting, or dragging it to another folder.",
      "image": "https://i.pinimg.com/736x/81/ad/6f/81ad6f8eb11f82b4ff1a1e27cddadb61.jpg",
      "topic": "cyber security",
      "author": "Joan"
    },
    {
      "id": "1cda",
      "title": "Western drivers remain sceptical of in-vehicle AI",
      "body": "A global study has unveiled a stark contrast in attitudes towards embracing in-vehicle AI between Eastern and Western markets, with European drivers particularly reluctant.\n\nThe research – conducted by MHP – surveyed 4,700 car drivers across China, the US, Germany, the UK, Italy, Sweden, and Poland, revealing significant geographical disparities in AI acceptance and understanding.\n\nAccording to the study, while AI is becoming integral to modern vehicles, European consumers remain hesitant about its implementation and value proposition.\n\nRegional disparities\nThe study found that 48 percent of Chinese respondents view in-car AI predominantly as an opportunity, while merely 23 percent of European respondents share this optimistic outlook. In Europe, 39 percent believe AI’s opportunities and risks are broadly balanced, while 24 percent take a negative stance, suggesting the risks outweigh potential benefits.\n\nUnderstanding of AI technology also varies significantly by region. While over 80 percent of Chinese respondents claim to understand AI’s use in cars, this figure drops to just 54 percent among European drivers, highlighting a notable knowledge gap.\n\nMarcus Willand, Partner at MHP and one of the study’s authors, notes: “The figures show that the prospect of greater safety and comfort due to AI can motivate purchasing decisions. However, the European respondents in particular are often hesitant and price-sensitive.”\n\nThe willingness to pay for AI features shows an equally stark divide. Just 23 percent of European drivers expressed willingness to pay for AI functions, compared to 39 percent of Chinese drivers. The study suggests that most users now expect AI features to be standard rather than optional extras.\n\n",
      "image": "https://i.pinimg.com/736x/be/57/88/be578886431772dabd94243d9b8cc915.jpg",
      "topic": "ai",
      "author": ""
    },
    {
      "id": "7693",
      "title": "Top Skills for Aspiring Software Engineers",
      "body": "The demand for skilled software engineers is soaring, but keeping up with the evolving landscape requires dedication to continuous learning. Whether you're starting out or looking to advance in your career, here are some must-have skills for the modern software engineer:\n\nProficiency in Programming Languages\nMastering languages like Python, JavaScript, Java, and newer ones like Rust is crucial. Each language has its strengths—Python is excellent for AI and data science, while JavaScript is essential for web development. Engineers who can code in multiple languages have an edge in today’s versatile job market.\n\nUnderstanding of Data Structures and Algorithms\nA solid understanding of data structures and algorithms forms the foundation of software engineering. Knowing how to efficiently manage data and solve problems is critical, whether you're developing mobile apps, handling databases, or designing AI models.\n\nFamiliarity with Cloud Platforms\nAs businesses move to the cloud, knowing how to work with cloud platforms like AWS, Google Cloud, and Microsoft Azure is increasingly important. Cloud skills allow engineers to develop scalable, flexible, and resilient applications.\n\nExperience with DevOps Practices\nDevOps is a key area, enabling engineers to automate and streamline workflows from development through to deployment. Skills in CI/CD, containerization with Docker, and infrastructure automation with tools like Kubernetes are invaluable.\n\nCybersecurity Awareness\nCybersecurity is no longer just for specialists; every engineer needs a basic understanding of security principles. Practices such as secure coding, encryption, and regular vulnerability assessments help build safer software.",
      "image": "https://i.pinimg.com/736x/24/68/a1/2468a19e048308eabf19eabc4a2ce7a7.jpg",
      "topic": "software engineering",
      "author": "James"
    },
    {
      "id": "7f7d",
      "title": "AI hallucinations gone wrong as Alaska uses fake stats in policy",
      "body": "The combination of artificial intelligence and policymaking can occasionally have unforeseen repercussions, as seen recently in Alaska.\n\nIn an unusual turn of events, Alaska legislators reportedly used AI-generated citations that were inaccurate to justify a proposed policy banning cellphones in schools. As reported by /The Alaska Beacon/, Alaska’s Department of Education and Early Development (DEED) presented a policy draft containing references to academic studies that simply did not exist.\n\nThe situation arose when Alaska’s Education Commissioner, Deena Bishop, used generative AI to draft the cellphone policy. The document produced by the AI included supposed scholarly references that were neither verified nor accurate, yet the document did not disclose the use of AI in its preparation. Some of the AI-generated content reached the Alaska State Board of Education and Early Development before it could be reviewed, potentially influencing board discussions.\n\nCommissioner Bishop later claimed that AI was used only to “create citations” for an initial draft and asserted that she corrected the errors before the meeting by sending updated citations to board members. However, AI “hallucinations”—fabricated information generated when AI attempts to create plausible yet unverified content—were still present in the final document that was voted on by the board.\n\nThe final resolution, published on DEED’s website, directs the department to establish a model policy for cellphone restrictions in schools. Unfortunately, the document included six citations, four of which seemed to be from respected scientific journals. However, the references were entirely made up, with URLs that led to unrelated content. The incident shows the risks of using AI-generated data without proper human verification, especially when making policy rulings.\n\nAlaska’s case is not one of a kind. AI hallucinations are increasingly common in a variety of professional sectors. For example, some legal professionals have faced consequences for using AI-generated, fictitious case citations in court. Similarly, academic papers created using AI have included distorted data and fake sources, presenting serious credibility concerns. When left unchecked, generative AI algorithms, which are meant to produce content based on patterns rather than factual accuracy, can easily produce misleading citations.\n\nThe reliance on AI-generated data in policymaking, particularly in education, carries significant risks. When policies are developed based on fabricated information, they may misallocate resources and potentially harm students. For instance, a policy restricting cellphone use based on fabricated data may divert attention from more effective, evidence-based interventions that could genuinely benefit students.\n\nFurthermore, using unverified AI data can erode public trust in both the policymaking process and AI technology itself. Such incidents underscore the importance of fact-checking, transparency, and caution when using AI in sensitive decision-making areas, especially in education, where impact on students can be profound.\n\nAlaska officials attempted to downplay the situation, referring to the fabricated citations as “placeholders” intended for later correction. However, the document with the “placeholders” was still presented to the board and used as the basis for a vote, underscoring the need for rigorous oversight when using AI.",
      "image": "https://i.pinimg.com/736x/14/37/c8/1437c87cbe57a6e6324048ba2abf9c55.jpg",
      "topic": "ai",
      "author": "Jane"
    },
    {
      "id": "1d64",
      "title": "How Google Unlocks and Measures Developer Productivity",
      "body": "Google’s engineering productivity team has about 2,000 engineers, mostly focused on making developer tools and processes more effective. Within, there’s a much smaller team that focuses on engineering productivity research — not necessarily the how, but more the why, when, what and how much.\n\nIt’s a mixed-method team that does both quantitative and qualitative research. It also is a mixed team of about half engineers and half user experience researchers, with folks who’ve previously worked as behavioral economists, social psychologists, industrial-organizational psychologists, and even someone from public health.\n\nThe social sciences background, Jaspan said, provides the necessary context. Logs analysis — a common starting point for developer productivity research — only provides part of the picture. “It tells you what developers are doing. But it doesn’t tell you why they’re doing that. It doesn’t tell you how they feel about it, [or] if what they’re doing is good or bad. It doesn’t tell you if there’s room for improvement. It only gives you a number, but you can’t interpret that number,” she said on the podcast. “Unless you have more of the qualitative side of the world, and you understand the behaviors and how those behaviors change over time, depending upon how you change the context.”\n\nThis is why the productivity research team hired their first UX researcher about five years ago to help design better surveys. Then, by pairing the UX folks with engineers, they are able to optimize not just what they were asking but the when and how. For example, this pairing enabled experience sampling, integrating surveys at the moment developers are running a build. The engineers can help provide both firsthand experience and technical solutions that scale UX research.\n\n“The direct access to subject matter experts who are way deep in it and who are at the top of their field is a really powerful augmentation to have in this quiver of arrows that is behavioral research methods,” Green said. “The domain expertise, the scalability, and the technical skills from the engineering side, combined with the wide variety of behavioral research methods and a facility accounting for things like bias, and the way people work, and what to watch out for in survey responses or interviews,” from the social scientists combine for UX research in a way that may be unique to Google. The UX folks have uncovered nonresponse bias and the engineers have discovered upstream bugs because things simply didn’t look right.\n\nDeveloper Productivity Is an Org-Wide Goal\nThis team’s first customer is the first-party developer team which builds the developer tooling for the whole org. The goal is to help them make improvements to infrastructure tooling, processes and best practices.\n\n“When they want to, for example, understand what makes developers productive and what could make them more productive, our data [and] our research is one of the places they go to understand how to even measure that,” Green said.\n\nThe productivity research team also collaborates with other teams including operations, real estate and workspaces, corporate engineering — who create tools for all Googlers, not just engineers — and other teams that can effect the overall developer experience. And then, of course, the learnings from developer productivity could benefit other non-technical teams. So long as cross-company communication ensues.\n\n“So when you focus on engineering productivity, you’re focusing on a big chunk of the Google population and so there’s wide interest in what we find,” Green said.\n\nThe Google engineering productivity team also acts as a conduit among different dev teams. As Jaspan said, “The company’s really big. People are doing different types of development. The people building the tools may not know about all the different types of work being done.”\n\nAll this makes for what Green calls a “playground of well-formed data” paired with engineers who have real experience with the problems at hand.\n\nSpeed, Ease and Quality Drive Productivity\nSo, if you had Google’s engineering budget, what would you measure?\n\nWith the rise of platform engineering and the consolidation of cross-organizational tooling, it’s become easier to track the technical developer experience. What’s still challenging is the effect of that technology on its human users and the effect of the people and processes around that experience. No single measurement could begin to capture that.\n\nThe developer productivity research team, Jaspan said, upholds a philosophy: There is no single metric that’s going to get you developer productivity. From here, she explained, the team triangulates across three intersecting axes:\n\nSpeed\nEase\nQuality\nFor example, Green once proposed – tongue in cheek, to make a point – that the quickest way to improve productivity would be to remove code reviews — which of course everyone resisted because, while it’d increase speed and ease of release, it’d decrease quality. And the team’s research has proven that code quality improves developer productivity.\n\nFor speed, they do measure logs, but they also measure engineers’ perception of how fast they think they’re going, as well as diary studies and interviews. Jaspan said, “It is both using multiple measures, but also making sure that they’re validated against each other.”\n\nMixed-Method Research Validates Data\nTo have a deeper study of Google’s software development behavior, the team performed a cross-tool logs study, ingesting logs from multiple developer tools. They also performed a diary study, in which, every few minutes, engineers wrote down what they were doing. They compared the two in order to create confidence in the data logs. Since each engineer works and perceives their work differently, it can become an apples-and-oranges situation, so they apply what’s called interrater reliability to calculate the agreement between the two studies.",
      "image": "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSj_yeTdx-R8FakIgLdvdEYs3qmJygiTF3dkQ&s",
      "topic": "software engineering",
      "author": "James"
    }
  ]
}